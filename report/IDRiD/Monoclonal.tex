\documentclass[conference]{IEEEtran}
\usepackage{graphicx}
\usepackage{lipsum}
\usepackage{cite}
% *** MATH PACKAGES ***
\usepackage{amsmath}
% *** SPECIALIZED LIST PACKAGES ***
\usepackage{algorithmic}
% *** ALIGNMENT PACKAGES ***
\usepackage{makecell}
\usepackage{array}
\usepackage{float}
\usepackage[utf8x]{inputenc}

\makeatletter
\def\endthebibliography{%
  \def\@noitemerr{\@latex@warning{Empty `thebibliography' environment}}%
  \endlist
}
\makeatother

\author{
    \IEEEauthorblockN{Shashank Reddy B\IEEEauthorrefmark{1}}
    \IEEEauthorblockA{\IEEEauthorrefmark{1} School of Computing\\   { { University of New South Wales}}
    \\\{z5222766\}@student.unsw.edu.au}
}

\begin{document}

\title{Computer Vision Individual Assignment}


% make the title area
\maketitle

% As a general rule, do not put math, special symbols or citations
% in the abstract
\begin{abstract}
 Monoclonal Gammopathy of Undetermined Significance (MGUS) occurs in up to 2\% of persons of the age 50 or older. Machine Learning methods are needed to learn the vital information embedded in the genetic samples, which in turn can be helpful to develop more robust and accurate models of clinical diagnostics. We use SEVEN methods with classification trees as one of our models. For each of the methods, we employed 10-fold cross validation to estimate the prediction error. Our results  produced are the comparison between the machine learning algorithms. 
 The results we achieved, proved to be better when certain preprocessing techniques were used for the specific application of an algorithm. The results varied when missing values are replaced with mode, mean, mean with class label etc. We considered removing the tuples where the missing values are found, with consequence of losing valuable data. The accuracy of 82.6\% is achieved by 	Support Vector Machines, followed by the K-Nearest Neighbor, Logistic Regression  .

\paragraph*{Keywords}
Optic Disc, Segmentation, Gaussian Blur, Canny, Hough Transform.

\end{abstract}

% no keywords



% For peer review papers, you can put extra information on the cover
% page as needed:
% \ifCLASSOPTIONpeerreview
% \begin{center} \bfseries EDICS Category: 3-BBND \end{center}
% \fi
%
% For peerreview papers, this IEEEtran command inserts a page break and
% creates the second title. It will be ignored for other modes.
\IEEEpeerreviewmaketitle



\section{Introduction}
\par MM, Multiple myeloma is a malignant plasma component of white blood cells (plasma cells) in the bone marrow. MM is related with an overproduction of an abnormal protein known as monoclonal protein (M-protein). Though this protein itself is not harmful to most people, if too much of this protein accumulates it often causes characteristic osteolytic lesions, anemia, renal failure, and hypercalcemia. \cite{monoclonal8} In contrast, monoclonal gammopathy of unknown significance (MGUS) is an asymptomatic plasma cell dyscrasia that is present in more than 3\% of the general white population older than age 50 and has an average multiple myeloma progression risk of 1\% per year. \cite{monoclonal9} \par

Traditional clinical practices rely on close surveillance as the tool for management of multiple myeloma precursor disease. Indeed, definition of MGUS has clearly evolved, and characterization of clinical subtypes and risk stratification models have led to better understanding of disease biology and probability of progression. Despite this, a number of inherent diagnostic challenges continue to plague physicians while managing their patients. Molecular tools used to better identify MGUS signature profiles provide answers to long-sought questions and dilemmas. Of course, more research effort is required in this area. Gaining molecular insight into multiple myeloma precursor disease may have a dramatic impact on clinical management in the future. As expected, several clinical investigations have already begun to study treatment options. \par

Though there is no known particular cause for accumulating of M-protein, the study found out some risk factors that might increase risk of developing MGUS. They include

\par
Machine Learning techniques have now been used both to classify different kinds of cancers which are morphologically indistinguishable and to predict response to therapy. In this paper, we discuss the possible Machine Learning techniques to predict the risk of progression of MGUS which has caused death in many people. Empirical results suggested that 10-fold cross validation may provide better accuracy estimates than the more common leave one out cross validation. We evaluate and compare each model against a set of metrics, resulted through the analysis of data from the MGUS data-set. The features that are included in the data set are age, sex, hgb (haemoglobin) etc. The data-set is explained in the Section \ref{ssec:describe}. Through this analysis using machine learning, can help in diagnosis of a patient. This method efficiently finds out if the progression of MGUS is probable for a certain case.

\section{Background}
\par
Patients with MGUS are at increased risk for progression to multiple myeloma or a related plasma-cell cancer. The risk of progression of MGUS to multiple myeloma or related disorders is about 1\% per year. \cite{monoclonal1,monoclonal2} In a comparison of patients with various monoclonal protein values, in which 0.5 g per deciliter or less was used as a reference value, it is found that the initial concentration of monoclonal protein was a statistically significant predictor of progression to multiple myeloma.

\par

The etiology of MGUS remains unclear and it is a current topic of investigation. Race seems to play a role given the observation that prevalence of MGUS is 2 to 3-fold higher in African-Americans and blacks from Africa compared with whites. \cite{monoclonal6, monoclonal7} Other identified risk factors for MGUS include older age, male sex, exposure to pesticides, and family history of MGUS or MM \cite{monoclonal9,monoclonal10,monoclonal11}. Thus, previous studies support a role for both genetic and environmental factors in the development of multiple myeloma and its precursor states. \cite{monoclonal12}

\section{Method}                                                                     
Fig. \ref{fig:flowchart} shows us an overview of the methodology pipeline. Our methodology consists of various steps: data pre-processing, feature selection, feature scaling and classification where we start with preparing the dataset, cleaning, training, fine tuning the algorithm, model training and testing. The data-set is taken from UCI\cite{uci}. We use scikit-learn \cite{scikit} and pandas library for all the steps involved in the methodology. Section \ref{ssec:describe} to section \ref{ssec:classification} consist of detailed information of the steps.     
\par              
%\begin{figure*}[t]
%	\centering
%	\includegraphics[scale=0.7]{../Images/gammo.png}
%	\caption{Methodology Pipeline Overview}
%	\label{fig:flowchart}
%\end{figure*}

\subsection{Data Description}
\label{ssec:describe}
We have a total of 10 attributes including class label \textbf{\textit{death}} which is a binary value. The other 9 attributes are,  

\begin{itemize}
\item \textbf{\textit{id}} is the patient identifier.
\item \textbf{\textit{age}} is the age of person in years at the time of detection of MGUS. 
\item \textbf{\textit{sex}} tells if person is male or female
\item \textbf{\textit{creat}} is creatinine level when MGUS is diagnosed.
\item \textbf{\textit{hgb}} is the amount of haemoglobin present in blood at time of MGUS diagnosis.
\item \textbf{\textit{mspike}} is the size of the monoclonal protein spike at diagnosis.
\item \textbf{\textit{ptime}} tells us the no.of days from MGUS until diagnosis of a plasma cell malignancy.
\item \textbf{\textit{pstat}} is a binary value which indicates if there is an interval end in an event.
\item \textbf{\textit{futime}} tells us the no.of days from diagnosis to last follow-up.
\end{itemize}


\subsection{Data Preprocessing}
\label{ssec:preprocess}
Incomplete and noisy data are common properties of real world databases. Data needs to be cleaned before it is processed for better efficiency and accurate outputs. There are a lot of pre-processing techniques that include cleaning and preparing the data for classification. Other pre-processing techniques include Integration and Transformation, Aggregation and Discretization.

The pre-processing done for our data are,
\begin{itemize}
\item \textbf{\textit{Filling missing values}} Missing values are filled in many ways and we used the mean of the total and substituted with our missing values. 
\item \textbf{\textit{Removal of unnecessary attributes}} Unnecessary attributes are removed so that it doesn't affect the performance of the model.
\item \textbf{\textit{Encoding the attribute values}} The values in the label \textit{sex} are in the form of characters \textit{M/F} which are transformed to \textit{1/0} using the help of label encoder.
\end{itemize} 

\subsection{Feature Selection}
\label{ssec:featureselect}
Selecting the right features for classification is very important and it  is the key factor for achieving a good performance for a model. 
\par
The models are having a very high deviation due to the presence of the \textit{id} label because of its sequence ordering nature. So, the \textit{id} label gets high feature importance, but, it is just a patient identifier which should be dropped from the data-set. The remaining labels are all important to process the output label. So the remaining 8 labels with 1384 patients are taken for classification. 
\subsection{Feature Scaling}
\label{ssec:featurescale}
Feature Scaling is important when the bounds between the labels are different from each other. The upper and lower bounds of the labels are very important and if they vary a lot in the data-set that could affect the performance of the model. There are many feature scaling techniques like standard scalar which makes use of mean and standard deviation, min-max scalar which normalizes based on the minimum and maximum values and robust scalar which makes use of the quartile ranges to normalize.
\par 
We used standard scalar as it fits the data based on the mean and the deviation of the data. Standard scalar is given by 
\begin{equation}
 y_{Scaling} = \sum\limits_{i=1}^{n}\frac{x_i - \mu(x) }{\sigma(x)}
\end{equation}
where n is the number of patients, $\mu(x)$ is the mean and 
$\sigma(x)$ is the standard deviation for the label.
\subsection{Classification}
\label{ssec:classification}
Classification is a 2-step process. In first step, a classifier is built to describe a predetermined set of data classes. This is the learning step and is done using the training data, where a classification algorithm builds the classifier by learning from that training set made up of data tuples and their associated class labels. It is also known as “Supervised learning”. 
\par
The data-set consists of 1384 patient details of which 80\% are taken for training the data and the remaining 20\% are taken for testing the data. The following are the learning algorithms that we used to predict the output label \textit{death},
\begin{enumerate}
\item Support Vector Machine
\item Linear Discriminant Analysis
\item Logistic Regression
\item Decision Tree Classifier
\item Naive Bayes
\item Random Forest Classifier
\item K - Nearest Neighbor
\end{enumerate}
\par
\subsubsection*{Support Vector Machine}
Support Vector Machines(SVM) are the supervised learning models that are used for classification of the data. SVMs are designed for both linear as well as non-linear classification. Linear data is rare and most of the existing data is non-linear. So, in \cite{svm}, they designed the SVM to fit the non-linear data by using the kernel trick which uses kernels in SVM to fit the data accordingly. There are many kernels that can be used on a data. As it is a hyper-parameter we need to experiment it with all the available kernels to find the best fit.
\begin{table}[ht]
\centering
 \begin{tabular}{|c| c c|} 
 \hline
 Kernel  & \thead{Train \\ Accuracy} & \thead{Test \\ Accuracy} \\ [0.5ex] 
 \hline
 Linear Function & 0.779 & 0.815\\ 

 Polynomial Function & 0.783 & 0.779\\
 
 Radial Basis Function & 0.807 & 0.826\\
 \hline
\end{tabular}
\vspace*{0.25cm}
\caption{SVM Kernels and their accuracies}
\label{table:svm}
\end{table}
\par
The following kernels and its accuracies that are used for our data are listed in the Table \ref{table:svm}. As we can see Radial Basis Function(RBF) kernel fits the data better than other experimented kernels because it has proved to be a generalizer for many data-sets and in many experiments it is assumed as priors for uncertain situations. RBF is also called squared exponential kernel or gaussian kernel.            

\subsubsection*{Decision Tree Classifier}
Decision tree is a, supervised learning algorithm, which is widely used classifier. Unlike Naïve Bayes, Logistic regression and other algorithms that belong to the supervised learning algorithm family, it can be used for solving both regression and classification problems. Even when the dataset has missing values, using Decision tree could result in a better output.
\par

When applied directly, Decision Tree causes the overfitting on \cite{monoclonal1} and not being generalized well to the new data. Therefore we pre-pruned the tree by setting the maximum depth $max_{depth}$ parameter to 3 as seen from \cite{dt}. Thus decreasing overfitting by limiting the depth. We observed a decrease in accuracy on the training set, but a significant increase in accuracy of test data. The feature importance plot of the decision tree classifier as shown in the figure \ref{feature_dtc} is given by,

%\begin{figure}[h!]
%	\centering
%	\includegraphics[width=3.5in]{../Images/images/feature_dtc.png}
%	\caption{Feature Importance plot of Decision Tree Classifier}	
%	\label{feature_dtc}
%\end{figure}
Information Gain and Gini Index are the two attribute selection measures used for selecting which attribute can be considered as the root node at each level. Figure \ref{gini} shows use the visualization of how gini index acts on the data-set.

%Addition of the data
%\begin{figure*}[h!]
%	\centering
%	\includegraphics[scale=0.4]{../Images/dtree2.png}
%	\caption{Visualization of Decision Tree Classifier using the gini index selection measure}	
%	\label{gini}
%\end{figure*}

\subsubsection*{K - Nearest Neighbor}
K Nearest neighbors is a classification algorithm that is used for regression predictive problems. As seen from \cite{knn}, building the model will only store the training data set. Only if a new input is chosen, it predicts and finds the closest data points in the training data: \textit{nearest neighbor}. KNN is commonly used for its easy of interpretation and minimal calculation time.
\par
The figure below shows the training and test data accuracy on the y-axis against number of neighbors on the x-axis. Consider choosing one single nearest neighbor, accuracy of prediction on training data set is \textbf{1}, perfect. But if more neighbors are considered, the training accuracy falls, showing us that using the single nearest neighbor leads to a model that is much complex.


%Figure of KNN
%\begin{figure}[h!]
%	\centering
%	\includegraphics[width=3.5in]{../Images/images/knn1.png}
%	\caption{Accuracies of KNN on train and test data}
%	\label{fig:knn}
%\end{figure}
\par
Figure \ref{fig:knn} indicates us to choose 17 or 18 neighbors. In our case K=17 neighbors has produced an accuracy of 81.2\% while K=13 neighbors has produced an accuracy of 82.3\%.


Thus we know how much the choice of factor \textbf{K} in the algorithm influences the outcome. The boundary becomes smoother with the increasing value of \textbf{K}. The training accuracy and test accuracy are the two parameters needed to access on different K-value, as shown the plot figure. The accuracy of KNN classifier significantly increases by increasing the number of data rows in the training set.



\section{Experiment}

%Pipeline
%Explain pipeline
\subsection{Metrics}
\label{sec:metrics}
The combination of all the steps are evaluated under different performance metrics, including accuracy, precision, recall and F-score for the binary classification. The metrics are defined as following,

\begin{equation}
Precision = \frac{1}{n}\sum\limits_{i=1}^{n} \frac{|X_i \cap Y_i|}{|Y_i|}
\end{equation}

\begin{equation}
Recall = \frac{1}{n}\sum\limits_{i=1}^{n} \frac{|X_i \cap Y_i|}{|X_i|}
\end{equation}

\begin{equation}
F_1 = \frac{1}{n}\sum\limits_{i=1}^{n} \frac{2|X_i \cap Y_i|}{|X_i| + |Y_i|}
\end{equation}

\begin{equation}
Accuracy = \frac{1}{n}\sum\limits_{i=1}^{n} \frac{|X_i \cap Y_i|}{|X_i \cup Y_i|}
\end{equation}

where $X_i$ is the set of predicted labels, $Y_i$ is the set of true labels and n is the number of samples.


\section{Results and Discussion}
Table \ref{table:1} shows us the model performance for all the algorithms we have experimented. The metrics used for evaluation are accuracy, precision, recall and $F_1$-score as shown in the section \ref{sec:metrics}. As we can see, the comparison between the algorithms helped us understand the nature of the algorithm as well as the data used, based on the metrics. The accuracies of all the other algorithms are close to each other by a fraction of percentage as they are tweaked to get the best accuracy using kernels, solvers and hyper-parameters. Except Naive Bayes all the accuracies of other algorithms are above 80\%. 
\par
The highest accuracy was achieved by Support Vector Machine with the radial basis function as the kernel. Its accuracy is 82.6\%. Therefore, the data is non-linear and it takes the form of probabilistic density function which has a global maximum. The lowest accuracy is achieved by Gaussian Naive Bayes but the difference in accuracies between the highest and lowest is only 2.9\%. When we consider the data to be linear, the accuracy falls below 60\%. Finally, the overall precision, recall and $F_1$-score for the algorithms are similar for many cases with the highest achieved by Support Vector Machine.
\par

\begin{table*}[htb]
\centering
 \begin{tabular}{|c| c c c c c|} 
 \hline
 Techniques & Training 		Accuracy & Test 	Accuracy & Precision & Recall & $F_1$-score \\ [0.5ex] 
 \hline
 Support Vector Machine & 0.807 & 0.826 & 0.83 & 0.83 & 0.82\\ 
 \hline
 Linear Discriminant Analysis & 0.786 & 0.815 & 0.81 & 0.82 & 0.81\\
 \hline
 Logistic Regression & 0.787 & 0.819 & 0.82 & 0.82 & 0.81\\
 \hline
 K - Nearest Neighbor & 0.819 & 0.823 & 0.82 & 0.82 & 0.82\\
 \hline
 Naive Bayes & 0.744 & 0.797 & 0.81 & 0.80 & 0.80\\  
 \hline
 Decision Tree Classifier & 0.796 & 0.815 & 0.81 & 0.82 & 0.82 \\
 \hline
 Random Forest Classifier & 0.799 & 0.808 & 0.81 & 0.81 & 0.79 \\[0.5ex] 
 \hline
\end{tabular}
\vspace*{0.25cm}
\caption{Model Performance of Algorithms}
\label{table:1}
\end{table*}

Table \ref{table:2} gives the performance measure for the output labels whose deaths is classified as \textbf{0}. As we can see, the values of the metrics, precision, recall and $F_1$-score are very less when compared to the metrics in table \ref{table:3}. That is because the number of patient with the output label \textbf{0} are very less when compared to the number of patients with output labels \textbf{1}. As the  $F_1$-score is a harmonic mean of precision and recall we can a reasonable values for it unlike the other two. The highest precision, recall and $F_1$-score is achieved by Random Forest Classifier, Decision Tree Classifier respectively. 
\begin{table}[H]
\centering
 \begin{tabular}{|c| c c c|} 
 \hline
 Techniques  & Precision & Recall & F1-score \\ [0.5ex] 
 \hline
 Support Vector Machine & 0.81 & 0.59 & 0.68 \\ 
 \hline
 Linear Discriminant Analysis & 0.77 & 0.60 & 0.68\\
 \hline
 Logistic Regression & 0.79 & 0.59 & 0.68\\
 \hline
 K - Nearest Neighbor & 0.77 & 0.64 & 0.70\\
 \hline
 Naive Bayes & 0.66 & 0.75 & 0.70\\  
 \hline
 Decision Tree Classifier & 0.72 & 0.69 & 0.71 \\
 \hline
 Random Forest Classifier & 0.82 & 0.51 & 0.63  \\[0.75ex] 
 \hline
\end{tabular}
\vspace*{0.25cm}
\caption{Performance Measures of the prediction when deaths label value is \textbf{0}}
\label{table:2}
\end{table}


The performance measures for prediction when the output labels is \textbf{1} is very high because of the dominance of the binary value \textbf{1} in the data. From Table \ref{table:3}, we can see that the highest precision, recall and $F_1$-score is achieved by Decision Tree Classifier, Support Vector Machines respectively. 
\begin{table}[H]
\centering
 \begin{tabular}{|c| c c c|} 
 \hline
 Techniques  & Precision & Recall & F1-score \\ [0.5ex] 
 \hline
 Support Vector Machine & 0.83 & 0.94 & 0.88 \\ 
 \hline
 Linear Discriminant Analysis & 0.83 & 0.92 & 0.87\\
 \hline
 Logistic Regression & 0.83 & 0.93 & 0.87\\
 \hline
 K - Nearest Neighbor & 0.84 & 0.91 & 0.88\\
 \hline
 Naive Bayes & 0.88 & 0.82 & 0.85\\  
 \hline
 Decision Tree Classifier & 0.86 & 0.87 & 0.87 \\
 \hline
 Random Forest Classifier & 0.81 & 0.95 & 0.87  \\[0.75ex] 
 \hline
\end{tabular}
\vspace*{0.25cm}
\caption{Performance Measures of the prediction when deaths label value is \textbf{1}}
\label{table:3}
\end{table}

\bibliographystyle{IEEEtran}
\bibliography{references}




% that's all folks
\end{document}


